[TOC]

# 关于华为的达芬奇架构和mindspore

----

## 达芬奇架构

为了实现AI在多平台场景之间的协同， 华为创新设计达芬奇计算架构，在不同体积的功耗条件下提供强劲的AI算力。 达芬奇架构，是华为自研的面向AI计算特征的全新计算架构，具备高算力、高能效、灵活可裁剪的特性，是实现万物智能的重要基础。具体来说，达芬奇架构采用3D Cube针对矩阵运算做加速，大幅提升单位功耗下的AI算力，每个AI Core可以在一个时钟周期内实现4096个MAC操作，相比传统的CPU和GPU实现数量级的提升。同时，为了提升AI计算的完备性和不同场景的计算效率，达芬奇架构还集成了向量、标量、硬件加速器等多种计算单元。同时支持多种精度计算，支撑训练和推理两种场景的数据精度要求，实现AI的全场景需求覆盖。

达芬奇架构设计核心： 以最小的计算代价增加矩阵乘的算力，实现更高的AI能效。

![preview](https://i.loli.net/2020/06/25/Au9JInP5dFUi6jX.png)

可以看到，对于整个架构而言，其主要由这样几个部分组成， 分别为：

#### 1. 3D Cube矩阵乘法单元

整个矩阵运算的核心在3D Cube中完成，其具体为$16 \times 16 \times 16$的三维结构，并且可以看到，其能够在一个时钟周期中实现4096个MAC操作，而且其三维的结构减少了芯片面积。 对于图中的整体架构而言， 实际上 Buffer L0A 和 Buffer L0B 负责输入矩阵，而Buffer L0C 则负责输出矩阵数据。 

在这里，实际上完成4096次运算，2D结构需要64行* 64列才能计算，而3D Cube只需要16 * 16 * 16 结构就能算出， 其中，64 * 64 结构带来的问题是： 运算周期长、时延长、利用率低。

#### 2. Vector 向量计算单元

虽然Cube的算力强大，然而其只能完成矩阵乘运算，而实际上，还有很多计算类型要依靠Vector向量计算单元来完成，其指令相对来说更加丰富，可以覆盖各种基本计算类型和许多定制的计算类型。

#### 3. Scalar 标量计算单元

Scalar标量运算单元主要负责整个AI core的标量运算，功能上可以看做是一个小CPU，完成整个程序的循环控制，分支判断，Cube、Vector等指令的地址和参数计算以及基本的算术运算等。 



#### 针对多种使用场景

正是由于达芬奇架构灵活可裁剪、高能效的特性，才能实现对上述多种复杂场景的AI运算处理。如图所示，不同的芯片可以应用在不同的场景之中，来实现相应的功能。华为选择开发统一架构，其优势在于对于广大开发者而言，在面对云端、边缘侧、端侧等全场景应用开发时，只需要进行一次算子开发和调试，就可以应用于不同平台，大幅降低了迁移成本。不仅开发平台语言统一，训练和推理框架也是统一的，开发者可以将大量训练模型放在本地和云端服务器，再将轻量级的推理工作放在移动端设备商行，获得一致的开发体验。

![img](https://i.loli.net/2020/06/25/DUgJkE5buOjslLv.jpg)

## mindspore

![image-20200625080405609](https://i.loli.net/2020/06/25/pBM7xE2dakr1TI3.png)

其主要分为MindSpore前端表示层、MindSpore计算图引擎和MindSpore后端运行时三层。

问题1 ： 关于自动微分技术 ，目前主要有三种自动微分技术：

1. 以tensorflow 为代表的基于静态数据流图的转换，可利用静态编译技术对网络进行性能优化，但受制于数据流图的表达形式，不能灵活表达控制流
2. 以pytorch 为代表的基于动态图的转换，虽然可以使用户可以灵活的使用控制流。而其缺点是运行时开销高，且不能运行静态编译技术对计算图进行性能优化
3. 基于源码转换的通用数据微分，也就是MindSpore采用的技术

### 第一讲： MindSpore分布式自动并行训练

#### 数据并行与模型并行

##### 数据并行

![image-20200625163744881](https://i.loli.net/2020/06/25/meOb7IRkyC9DxA6.png)

将模型在不同板卡上进行相应的复制，对于batch 进行分布。 实现训练间的同步，要进行梯度聚合，要注意数据同步。 

![image-20200625165134755](https://i.loli.net/2020/06/25/6Bd7N1Q5UyCzHxG.png)

![image-20200625165149735](https://i.loli.net/2020/06/25/5lvXJHQ6Bxk2iaS.png)

##### 模型并行

模型内存过大，分为层内模型并行和层间模型并行，对于mindspore 而言，其主要支持层内模型并行的方式。 相比于数据并行而言，模型并行的难度更大，对开发者的要求更高。考虑内存上限，在性能上要兼顾通信开销，还要关心张量排布，切分的维度。 主流的框架主要通过用户自主切分的方式，以pytorch为例，其要通过手动实现相应的代码，具体如下：

![image-20200625165747145](https://i.loli.net/2020/06/25/IRqliLcCWO7y9kK.png)

